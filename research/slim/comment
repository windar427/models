对growth的理解:
表示每个dense block中每层输出的feature map个数, 如果block中有5层，则该block输出的特征图个数为5growth,
根据dense block的设计，后面几层可以得到前面所有层的输入，因此concat后的输入channel还是比较大的。
另外这里每个dense block的33卷积前面都包含了一个1*1的卷积操作，就是所谓的bottleneck layer，目的是减少输入的feature map数量，既能降维减少计算量，又能融合各个通道的特征.
对稠密链接的理解:
每层以之前层的输出为输入，对于有L层的传统网络，一共有LL个连接，对于DenseNet，则有L*(L+1)/2个连接。 通过加深网络结构，提升分类结果。
加深网络结构首先需要解决的是梯度消失问题，尽量缩短前层和后层之间的连接。
后面可以直接用到原始输入信息，同时还用到了之前层对原始层信息处理后的信息，这样能够最大化信息的流动。
反向传播过程中，原始层的梯度信息包含了损失函数直接对原始层的导数，有利于梯度传播。
稠密链接最终形成了densenet的以下优点： 1.有效解决梯度消失问题 2.强化特征传播 3.支持特征重用